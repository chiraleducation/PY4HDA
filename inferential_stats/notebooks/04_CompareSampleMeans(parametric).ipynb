{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Sample Means (parametric)\n",
    "- Student’s t-test\n",
    "- Paired Student’s t-test\n",
    "- Analysis of Variance Test (ANOVA)\n",
    "- Repeated Measures ANOVA Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-test\n",
    "- It compares **mean** of **two groups**\n",
    "- It is a parametric statistical test.\n",
    "- It's used to study if there is **statistical difference** between **two groups**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of t-test\n",
    "- One sample t-test\n",
    "- Paired t-test(Dependent)\n",
    "- Unpaired t-test(Independent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpaired t-test also have 2 categories \n",
    "\n",
    "- Student's t-test\n",
    "  - Equal variance\n",
    "  - Two sample t-test\n",
    "- Welch t-test\n",
    "  - Unequal variance\n",
    "  - Unequal variance t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of t-test\n",
    "- One sample t-test(for one sample)\n",
    "- Paired t-test(for dependent samples)\n",
    "- Student t-test(When sample size and variance are equal)\n",
    "- Welch t-test(When sample size and variance are different)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "sns.set(font_scale=2, palette= \"viridis\")\n",
    "from sklearn.preprocessing import scale\n",
    "import researchpy as rp\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/pulse_data.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Sample t-test\n",
    "It compares the mean of one sample \n",
    "- Known(from previous study) mean ($\\mu$)\n",
    "- Hypothetical mean($\\mu$)\n",
    "\n",
    "### Interpretation\n",
    "__Question: Is the average height different from a established height?__\n",
    "\n",
    "__Hypothesis__ \n",
    "- H0: The average age is $\\mu$ = 20\n",
    "- Ha: The average age is $\\mu$ $\\neq$ 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Height'].describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.skew(data['Height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kurtosis(data['Height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data['Height'], kde=True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(data['Height'], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p,  = stats.ttest_1samp(data['Age'], 20)\n",
    "print(f'stat={stat}, p-value={p}') \n",
    "alpha = 0.05 \n",
    "if p > alpha:\n",
    "    print('The average age is 20(fail to reject H0, result is not significant)')\n",
    "else:\n",
    "    print('Ha: The average age is not 20(reject H0, result is significant)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student's t-test\n",
    "- The independent t-test is also called the two sample t-test, student’s t-test, or unpaired t-test. \n",
    "- It’s an univariate test that tests for a significant difference between the mean of two unrelated groups.\n",
    "- It compares the mean of two independent samples.\n",
    "\n",
    "## Assumptions\n",
    "The assumptions that the data must meet in order for the test results to be valid are:\n",
    "- The independent variable (IV) is categorical with at least two levels (groups)\n",
    "- The dependent variable (DV) is continuous which is measured on an interval or ratio scale\n",
    "- The distribution of the two groups should follow the normal distribution\n",
    "- The variances between the two groups are equal\n",
    "    - This can be tested using statistical tests including Levene’s test, F-test, and Bartlett’s test.\n",
    "\n",
    "If any of these assumptions are violated then another test should be used.\n",
    "\n",
    "\n",
    "### Interpretation\n",
    "__Question: Is there a difference in the height between men and women?__\n",
    "\n",
    "__Hypothesis__\n",
    "- H0: the means of the samples are equal.\n",
    "- Ha: the means of the samples are unequal.\n",
    "\n",
    "__References__\n",
    "\n",
    "https://pythonfordatascienceorg.wordpress.com/independent-t-test-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Height'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Gender')['Height'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.boxplot(data=data, x='Height', y=\"Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsets of data \n",
    "sample_01 = data[(data['Gender'] == 'Male')]\n",
    "\n",
    "sample_02 = data[(data['Gender'] == 'Female')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_01.shape, sample_02.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample size should be equal \n",
    "sample_01 = sample_01.sample(50)\n",
    "sample_01.shape, sample_02.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Hypothesis Being Tested\n",
    "\n",
    "* Null Hypothesis (H0): u1 = u2, which translates to the mean of `sample_01` is equal to the mean of `sample 02`\n",
    "* Alternative Hypothesis (H1): u1 ? u2, which translates to the means of `sample01` is not equal to `sample 02`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homogeneity of variance\n",
    "Of these tests, the most common assessment for homogeneity of variance is Levene's test. The Levene's test uses an F-test to test the null hypothesis that the variance is equal across groups. A p value less than .05 indicates a violation of the assumption.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Levene%27s_test\n",
    "\n",
    "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.levene.html\n",
    "\n",
    "To know, [Click here](https://en.wikipedia.org/wiki/Levene%27s_test) why we test for levene's test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levene's test \n",
    " Levene's test is an inferential statistic used to assess the equality of variances for a variable calculated for two or more groups\n",
    " \n",
    " ### Interpretation\n",
    " - H0: The variances are equal between two groups \n",
    " - Ha: The variances are not equal between two groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.levene(sample_01['Height'], sample_02['Height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a356f071a967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevene\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Height'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_02\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Height'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'stat={stat}, p-value={p}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The variances are equal between two groups(reject H0, not significant)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "stat, p,  = stats.levene(sample_01['Height'], sample_02['Height'])\n",
    "print(f'stat={stat}, p-value={p}')\n",
    "if p > alpha:\n",
    "    print('The variances are equal between two groups(reject H0, not significant)')\n",
    "else:\n",
    "    print('The variances are not equal between two groups(reject H0, significant)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__If the test were to be significant, a viable alternative would be to conduct a Welch’s t-test__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution  of Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.histplot(sample_01['Height'], kde=True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for normality by Q-Q plot graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "stats.probplot(sample_01['Height'], plot=plt, dist='norm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__the data should be on the red line. If there are data points that are far off of it, it’s an indication that there are some deviations from normality.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking normal distribution by `shapiro method`\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html\n",
    "- https://stats.stackexchange.com/questions/15696/interpretation-of-shapiro-wilk-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_value = stats.shapiro(sample_01['Height'])\n",
    "print(f'statistic = {stat}, p-value = {p_value}')\n",
    "alpha = 0.05 \n",
    "if p_value > alpha: \n",
    "    print(\"The sample has normal distribution(Fail to reject the null hypothesis, the result is not significant)\")\n",
    "else: \n",
    "    print(\"The sample does not have a normal distribution(Reject the null hypothesis, the result is significant)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_value = stats.shapiro(sample_02['Height'])\n",
    "print(f'statistic = {stat}, p-value = {p_value}')\n",
    "alpha = 0.05 \n",
    "if p_value > alpha: \n",
    "    print(\"The sample has normal distribution(Fail to reject the null hypothesis, the result is not significant)\")\n",
    "else: \n",
    "    print(\"The sample does not have a normal distribution(Reject the null hypothesis, the result is significant)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:-__[See here](https://stats.stackexchange.com/questions/15696/interpretation-of-shapiro-wilk-test)\n",
    "\n",
    "W test statistic and the second value is the p-value. Since the test statistic does not produce a significant p-value, the data is indicated to be normally distributed\n",
    "\n",
    "The data met all the assumptions for the t-test which indicates the results can be trusted and the t-test is an appropriate test to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent t-test by using `scipy.stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(sample_01['Height'], sample_02['Height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p,  = stats.ttest_ind(sample_01['Height'], sample_02['Height'])\n",
    "print(f'stat={stat}, p-value={p}')\n",
    "if p > alpha:\n",
    "    print('Accept null hypothesis that the means are equal between two groups')\n",
    "else:\n",
    "    print('Reject the null hypothesis that the means are not equal between two groups.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent t-test using `researchpy`\n",
    "\n",
    "https://researchpy.readthedocs.io/en/latest/ttest_documentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives, results = rp.ttest(sample_01['Height'], sample_02['Height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired t-test\n",
    "- It compares the mean between two related samples.(each subject is measured twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_reading = pd.read_csv('../data/blood_pressure.csv')\n",
    "bp_reading.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_reading.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_reading.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_reading[['bp_before', 'bp_after']].boxplot(figsize=(12, 8))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Hypothesis Being Tested\n",
    "* Null Hypothesis (H0): u1 = u2, which translates to the mean of sample 01 is equal to the mean of sample 02\n",
    "* Alternative hypothesis (Ha): u1 ? u2, which translates to the means of sample 01 is not equal to sample 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumption check \n",
    "\n",
    "* The samples are independently and randomly drawn\n",
    "* The distribution of the residuals between the two groups should follow the normal distribution\n",
    "* The variances between the two groups are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p,  = stats.levene(bp_reading['bp_after'], bp_reading['bp_before'])\n",
    "print(f'stat={stat}, p-value={p}')\n",
    "alpha = 0.05 \n",
    "if p > alpha:\n",
    "    print('Accept null hypothesis that the variances are equal between two groups')\n",
    "else:\n",
    "    print('Reject the null hypothesis that the variances are not equal between two groups.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_reading['bp_diff'] = scale(bp_reading['bp_after'] - bp_reading['bp_before'])\n",
    "bp_reading.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_reading[['bp_diff']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_reading[['bp_diff']].hist(figsize=(12, 8))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "stats.probplot(bp_reading['bp_diff'], plot=plt)\n",
    "\n",
    "plt.title('Blood pressure difference Q-Q plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:-** The corresponding points are lies very close to line that means are our sample data sets are normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_value = stats.shapiro(bp_reading['bp_diff'])\n",
    "print(f'statistic = {stat}, p-value = {p_value}')\n",
    "alpha = 0.05 \n",
    "if p_value > alpha: \n",
    "    print(\"The sample has normal distribution(Fail to reject the null hypothesis, the result is not significant)\")\n",
    "else: \n",
    "    print(\"The sample does not have a normal distribution(Reject the null hypothesis, the result is significant)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Researchpy\n",
    "- https://researchpy.readthedocs.io/en/latest/ttest_documentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.ttest(bp_reading['bp_after'], bp_reading['bp_before'], \n",
    "         paired = True, equal_variances=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welch's t-test\n",
    "- It compares the mean of two independent samples.\n",
    "- It assumes:\n",
    "  - Samples don't have equal variance\n",
    "  - Sample size is not equal. \n",
    "  \n",
    "Welch's t-test Assumptions\n",
    "Like every test, this inferential statistic test has assumptions. The assumptions that the data must meet in order for the test results to be valid are:\n",
    "\n",
    "- The independent variable (IV) is categorical with at least two levels (groups)\n",
    "- The dependent variable (DV) is continuous which is measured on an interval or ratio scale\n",
    "- The distribution of the two groups should follow the normal distribution\n",
    "If any of these assumptions are violated then another test should be used.\n",
    "\n",
    "## Interpretation\n",
    "- **Null hypothesis (H0):** u1 = u2, which translates to the mean of sample 1 is equal to the mean of sample 2\n",
    "- **Alternative hypothesis (HA):** u1 ≠ u2, which translates to the mean of sample 1 is not equal to the mean of sample 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_mortality = pd.read_csv('../data/USRegionalMortality.csv')\n",
    "us_mortality.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_01 = us_mortality[(us_mortality['Cause'] == \"Heart disease\") & (us_mortality['Sex'] == 'Male')]\n",
    "\n",
    "sample_02 = us_mortality[(us_mortality['Cause'] == \"Heart disease\") & (us_mortality['Sex'] == 'Female')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_01.shape, sample_02.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_value =stats.shapiro(sample_01['Rate'])\n",
    "print(f'statistic = {stat}, p-value = {p_value}')\n",
    "alpha = 0.05 \n",
    "if p_value > alpha: \n",
    "    print(\"The sample has normal distribution(Fail to reject the null hypothesis, the result is not significant)\")\n",
    "else: \n",
    "    print(\"The sample does not have a normal distribution(Reject the null hypothesis, the result is significant)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_value =stats.shapiro(sample_02['Rate'])\n",
    "print(f'statistic = {stat}, p-value = {p_value}')\n",
    "alpha = 0.05 \n",
    "if p_value > alpha: \n",
    "    print(\"The sample has normal distribution(Fail to reject the null hypothesis, the result is not significant)\")\n",
    "else: \n",
    "    print(\"The sample does not have a normal distribution(Reject the null hypothesis, the result is significant)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(sample_01['Rate'], sample_02['Rate'], equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p_value =stats.ttest_ind(sample_01['Rate'], sample_02['Rate'], equal_var = False)\n",
    "print(f'statistic = {stat}, p-value = {p_value}')\n",
    "alpha = 0.05 \n",
    "if p_value > alpha: \n",
    "    print(\"The sample means are equal (Fail to reject the null hypothesis, the result is not significant)\")\n",
    "else: \n",
    "    print(\"The sample means are not equal (Reject the null hypothesis, the result is significant)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Researchpy\n",
    "- https://researchpy.readthedocs.io/en/latest/ttest_documentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des, res = rp.ttest(sample_01['Rate'], sample_01['Rate'],\n",
    "                            equal_variances= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
